{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reuters.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanuj/tf-basics/blob/master/reuters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "tQTqEK96v2U8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "b413dfb4-b9de-467a-9c6b-53948feb843d"
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "from keras.datasets import reuters\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
        "\n",
        "# transform to one hot vectors\n",
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "  results = np.zeros((len(sequences), dimension))\n",
        "  for i, sequence in enumerate(sequences):\n",
        "    results[i, sequence] = 1.\n",
        "  return results\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)\n",
        "\n",
        "def to_one_hot(labels, dimension=46):\n",
        "  results = np.zeros((len(labels), dimension))\n",
        "  for i, label in enumerate(labels):\n",
        "    results[i, label] = 1.\n",
        "  return results\n",
        "\n",
        "one_hot_train_labels = to_one_hot(train_labels)\n",
        "one_hot_test_labels = to_one_hot(test_labels)\n",
        "\n",
        "# define model\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# split train and validation data\n",
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "\n",
        "y_val = one_hot_train_labels[:1000]\n",
        "partial_y_train = one_hot_train_labels[1000:]\n",
        "\n",
        "# train the model\n",
        "history = model.fit(partial_x_train, partial_y_train, epochs=20,\n",
        "                    batch_size=512, validation_data=(x_val, y_val))\n",
        "\n",
        "# evaluate on test data\n",
        "results = model.evaluate(x_test, one_hot_test_labels)\n",
        "print(results)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7982 samples, validate on 1000 samples\n",
            "Epoch 1/20\n",
            "7982/7982 [==============================] - 2s 311us/step - loss: 2.5322 - acc: 0.4955 - val_loss: 1.7208 - val_acc: 0.6120\n",
            "Epoch 2/20\n",
            "7982/7982 [==============================] - 2s 253us/step - loss: 1.4452 - acc: 0.6879 - val_loss: 1.3459 - val_acc: 0.7060\n",
            "Epoch 3/20\n",
            "7982/7982 [==============================] - 2s 251us/step - loss: 1.0953 - acc: 0.7651 - val_loss: 1.1708 - val_acc: 0.7430\n",
            "Epoch 4/20\n",
            "7982/7982 [==============================] - 2s 256us/step - loss: 0.8697 - acc: 0.8165 - val_loss: 1.0793 - val_acc: 0.7590\n",
            "Epoch 5/20\n",
            "7982/7982 [==============================] - 2s 254us/step - loss: 0.7034 - acc: 0.8472 - val_loss: 0.9844 - val_acc: 0.7810\n",
            "Epoch 6/20\n",
            "7982/7982 [==============================] - 2s 252us/step - loss: 0.5667 - acc: 0.8802 - val_loss: 0.9411 - val_acc: 0.8040\n",
            "Epoch 7/20\n",
            "7982/7982 [==============================] - 2s 252us/step - loss: 0.4581 - acc: 0.9048 - val_loss: 0.9083 - val_acc: 0.8020\n",
            "Epoch 8/20\n",
            "7982/7982 [==============================] - 2s 251us/step - loss: 0.3695 - acc: 0.9231 - val_loss: 0.9363 - val_acc: 0.7890\n",
            "Epoch 9/20\n",
            "7982/7982 [==============================] - 2s 257us/step - loss: 0.3032 - acc: 0.9315 - val_loss: 0.8917 - val_acc: 0.8090\n",
            "Epoch 10/20\n",
            "7982/7982 [==============================] - 2s 254us/step - loss: 0.2537 - acc: 0.9414 - val_loss: 0.9071 - val_acc: 0.8110\n",
            "Epoch 11/20\n",
            "7982/7982 [==============================] - 2s 252us/step - loss: 0.2187 - acc: 0.9471 - val_loss: 0.9177 - val_acc: 0.8130\n",
            "Epoch 12/20\n",
            "7982/7982 [==============================] - 2s 253us/step - loss: 0.1873 - acc: 0.9508 - val_loss: 0.9027 - val_acc: 0.8130\n",
            "Epoch 13/20\n",
            "7982/7982 [==============================] - 2s 249us/step - loss: 0.1703 - acc: 0.9521 - val_loss: 0.9323 - val_acc: 0.8110\n",
            "Epoch 14/20\n",
            "7982/7982 [==============================] - 2s 249us/step - loss: 0.1536 - acc: 0.9554 - val_loss: 0.9689 - val_acc: 0.8050\n",
            "Epoch 15/20\n",
            "7982/7982 [==============================] - 2s 250us/step - loss: 0.1390 - acc: 0.9560 - val_loss: 0.9686 - val_acc: 0.8150\n",
            "Epoch 16/20\n",
            "7982/7982 [==============================] - 2s 250us/step - loss: 0.1313 - acc: 0.9560 - val_loss: 1.0220 - val_acc: 0.8060\n",
            "Epoch 17/20\n",
            "7982/7982 [==============================] - 2s 252us/step - loss: 0.1217 - acc: 0.9579 - val_loss: 1.0254 - val_acc: 0.7970\n",
            "Epoch 18/20\n",
            "7982/7982 [==============================] - 2s 251us/step - loss: 0.1198 - acc: 0.9582 - val_loss: 1.0430 - val_acc: 0.8060\n",
            "Epoch 19/20\n",
            "7982/7982 [==============================] - 2s 250us/step - loss: 0.1138 - acc: 0.9597 - val_loss: 1.0955 - val_acc: 0.7970\n",
            "Epoch 20/20\n",
            "7982/7982 [==============================] - 2s 247us/step - loss: 0.1111 - acc: 0.9593 - val_loss: 1.0674 - val_acc: 0.8020\n",
            "2246/2246 [==============================] - 0s 166us/step\n",
            "[1.2092602541695083, 0.778717720444884]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}